\chapter{Performance-Messungen der parallelen Implementation}

\section{Evaluierung der Optimierungen}

\subsection{Parallelisierung}

\begin{correctmore}
	- Speedup: 2-5x (geschätzt; ohne mehr nodes)
	- linear mit Anzahl der Nodes bis Anzahl der Bildpaare
	- anschließend Stagnation bis zu 2* Anzahl d. Nodes, weil bis da hin einige CPUs immer noch alleine a einem Bildpaar rechnet und alle anderen auf diesen warten müssen
\end{correctmore}

\subsection{Optimierung von Python Engpässen}

\subsubsection{Nutzen bereits optimierter Funktionen}

\begin{correctmore}
	- Speedup: 2.5x
\end{correctmore}

\subsubsection{Kompilieren}

\paragraph{Gesamtes Programm}

\begin{correctmore}
	- kompilieren des kompletten Projektes mit Cython
	- funktioniert, aber Ergebnisse bringen nicht gewünschten Speedup bzw. nur manchmal
	--> Ansatz verworfen
\end{correctmore}

\paragraph{numba}

\begin{correctmore}
	- kein speedup
	- cpython compiler besser, da er direkt für python gemacht wurde
	- bereits viel durch intrinsics optimiert
\end{correctmore}

\paragraph{Cython}

\begin{correctmore}
	- ein wenig besser als intrinsics, da typinformationen fest einprogrammiert sind
	- kein tatsächlicher Unterschied zu intrinsics
\end{correctmore}

\section{Einfluss der Parameter}

\begin{correctmore}
	- Sweet-Spot: ca. 3*#Bildpaare
	- skalliert mit mehr Nodes, aber später nicht mehr gut
	- skaliert besser mit mehr Bildpaaren
\end{correctmore}

\section{Skalierung}

\subsection{Skalierungsfaktor}

\begin{correctme}
	- schwache skalierung da
	- skaliert aber stark deutlich besser
\end{correctme}

\subsection{Sättigung}

\begin{correctmore}
	- erster Sättigungspunkt bei #nodes=#bildpaare, da dann alle CPUs zu 100\% ausgelastet sind --> stagniert bis 2*#nodes=#bildpaare
	- neues Bottleneck: Rest des Speckle-trackings (nicht paralleliserter Teil) + Gradientenintegration und nicht parallelisierter Rest der Bildverarbeitungsroutine
	--> nur begrenzte Menge an Daten verfügbar
\end{correctmore}