\chapter{Performance-Messungen der parallelen Implementation}

\section{Evaluierung der Optimierungen}

\subsection{Parallelisierung}

\begin{correctmore}
	- Speedup: 2-5x (geschätzt; ohne mehr nodes)
	- linear mit Anzahl der Nodes bis Anzahl der Bildpaare
\end{correctmore}

\subsection{Optimierung von Python Engpässen}

\subsubsection{Nutzen bereits optimierter Funktionen}

\begin{correctmore}
	- Speedup: 2.5x
\end{correctmore}

\subsubsection{Kompilieren}

\paragraph{Gesamtes Programm}

\begin{correctmore}
	- kompilieren des kompletten Projektes mit Cython
	- funktioniert, aber Ergebnisse bringen nicht gewünschten Speedup bzw. nur manchmal
	--> Ansatz verworfen
\end{correctmore}

\paragraph{numba}

\begin{correctmore}
	- kaum speedup
	- cpython compiler besser, da er direkt für python gemacht wurde
	- bereits viel durch intrinsics optimiert
\end{correctmore}

\paragraph{Cython}

\begin{correctmore}
	- ein wenig besser als intrinsics, da typinformationen fest einprogrammiert sind
\end{correctmore}

\section{Einfluss der Parameter}

\begin{correctmore}
	- Algorithmus in verschiedenen Konfigurationen benchmarken (Anzahl der Nodes, verschiedene Datensets, ...)
	- Performance Sweet-Spot finden
\end{correctmore}

\section{Skalierung}

\subsection{Skalierungsfaktor}

\correctme{ - auf Skalierungsfaktor eingehen und diesen in Bezug zu Parametern und verwendeter Hardware setzen}

\subsection{Sättigung}

\begin{correctmore}
	- Sättigungspunkt -grund beschreiben
	- Sättigungsgrund:
	-> Framepaketgröße: Rechenaufwand >> Kopieraufwand -> keine weitere Optimierung des Kopieraufwandes möglich
	-> Anzahl der Nodes: Kopieraufwand übersteigt Rechenaufwand bzw. nähert sich an
	-> nur begrenzte Menge an Datenverfügbar
\end{correctmore}